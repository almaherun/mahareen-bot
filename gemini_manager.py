"""
Ù…Ø¯ÙŠØ± Google Gemini API Ù…Ø¹ Ù†Ø¸Ø§Ù… ØªØ¨Ø¯ÙŠÙ„ ØªÙ„Ù‚Ø§Ø¦ÙŠ
"""

import os
import logging
import google.generativeai as genai
from typing import Optional

logger = logging.getLogger(__name__)

class GeminiManager:
    def __init__(self):
        self.api_keys = self._load_api_keys()
        self.current_index = int(os.getenv('CURRENT_API_INDEX', 0))
        self.model = None
        self._initialize_model()
    
    def _load_api_keys(self) -> list:
        """ØªØ­Ù…ÙŠÙ„ Ù…ÙØ§ØªÙŠØ­ API Ù…Ù† Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©"""
        keys_str = os.getenv('GEMINI_API_KEYS', '')
        if not keys_str:
            logger.error("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ÙØ§ØªÙŠØ­ Gemini API")
            return []
        
        keys = [key.strip() for key in keys_str.split(',') if key.strip()]
        logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(keys)} Ù…ÙØ§ØªÙŠØ­ API")
        return keys
    
    def _initialize_model(self):
        """ØªÙ‡ÙŠØ¦Ø© Ù†Ù…ÙˆØ°Ø¬ Gemini"""
        if not self.api_keys:
            logger.error("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…ÙØ§ØªÙŠØ­ API Ù…ØªØ§Ø­Ø©")
            return
        
        try:
            current_key = self.api_keys[self.current_index]
            genai.configure(api_key=current_key)
            self.model = genai.GenerativeModel('gemini-pro')
            logger.info(f"âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Gemini Ø¨Ø§Ù„Ù…ÙØªØ§Ø­ Ø±Ù‚Ù… {self.current_index + 1}")
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© Gemini: {e}")
            self._try_next_key()
    
    def _try_next_key(self):
        """Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„ØªØ§Ù„ÙŠ"""
        if len(self.api_keys) <= 1:
            logger.error("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…ÙØ§ØªÙŠØ­ Ø¨Ø¯ÙŠÙ„Ø©")
            return
        
        self.current_index = (self.current_index + 1) % len(self.api_keys)
        logger.info(f"ğŸ”„ Ø§Ù„ØªØ¨Ø¯ÙŠÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ù…ÙØªØ§Ø­ Ø±Ù‚Ù… {self.current_index + 1}")
        
        try:
            current_key = self.api_keys[self.current_index]
            genai.configure(api_key=current_key)
            self.model = genai.GenerativeModel('gemini-pro')
            logger.info("âœ… ØªÙ… Ø§Ù„ØªØ¨Ø¯ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­")
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ Ø§Ù„ØªØ¨Ø¯ÙŠÙ„: {e}")
            if self.current_index < len(self.api_keys) - 1:
                self._try_next_key()
    
    async def generate_response(self, prompt: str, context: str = "") -> Optional[str]:
        """ØªÙˆÙ„ÙŠØ¯ Ø±Ø¯ Ù…Ù† Gemini"""
        if not self.model:
            return "âŒ Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ØºÙŠØ± Ù…ØªØ§Ø­ Ø­Ø§Ù„<|im_start|>"
        
        try:
            # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø³ÙŠØ§Ù‚ ÙˆØ§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª
            full_prompt = f"""
Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠØ© Ø§Ù„Ù…Ø§Ù‡Ø±ÙˆÙ† Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„ÙƒØ±ÙŠÙ….

Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠØ©:
{context}

ØªØ¹Ù„ÙŠÙ…Ø§Øª Ù…Ù‡Ù…Ø©:
- Ø£Ø¬Ø¨ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙ‚Ø·
- ÙƒÙ† Ù…ÙÙŠØ¯<|im_start|> ÙˆÙ…Ù‡Ø°Ø¨Ø§Ù‹
- Ø±ÙƒØ² Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠØ©
- Ø¥Ø°Ø§ Ù„Ù… ØªØ¹Ø±Ù Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©ØŒ ÙˆØ¬Ù‡ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù„Ù„ØªÙˆØ§ØµÙ„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
- Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¥ÙŠÙ…ÙˆØ¬ÙŠ Ø¨Ø´ÙƒÙ„ Ù…Ù†Ø§Ø³Ø¨

Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {prompt}

Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:
"""
            
            response = self.model.generate_content(full_prompt)
            
            if response and response.text:
                logger.info("âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø±Ø¯ Ù…Ù† Gemini Ø¨Ù†Ø¬Ø§Ø­")
                return response.text.strip()
            else:
                logger.warning("âš ï¸ Ø±Ø¯ ÙØ§Ø±Øº Ù…Ù† Gemini")
                return "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† ÙÙ‡Ù… Ø³Ø¤Ø§Ù„Ùƒ. ÙŠØ±Ø¬Ù‰ Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØªÙ‡."
                
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Gemini: {e}")
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªØ¨Ø¯ÙŠÙ„ Ù„Ù„Ù…ÙØªØ§Ø­ Ø§Ù„ØªØ§Ù„ÙŠ
            if "quota" in str(e).lower() or "limit" in str(e).lower():
                logger.info("ğŸ”„ Ø§Ù†ØªÙ‡Øª Ø­ØµØ© Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ø­Ø§Ù„ÙŠØŒ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ¨Ø¯ÙŠÙ„...")
                self._try_next_key()
                
                # Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ù…Ø¹ Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ø¬Ø¯ÙŠØ¯
                try:
                    response = self.model.generate_content(full_prompt)
                    if response and response.text:
                        return response.text.strip()
                except Exception as e2:
                    logger.error(f"âŒ ÙØ´Ù„ Ù…Ø¹ Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ø¬Ø¯ÙŠØ¯: {e2}")
            
            return "âŒ Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø§Ø­Ù‚åº”ç”¨æŸ¥çœ‹Ù†Ø§ Ù…Ø¨Ø§Ø´Ø±Ø©."
    
    def get_current_key_info(self) -> dict:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ø­Ø§Ù„ÙŠ"""
        return {
            "current_index": self.current_index,
            "total_keys": len(self.api_keys),
            "has_model": self.model is not None
        }
